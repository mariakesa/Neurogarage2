{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label truths: [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0]\n",
      "Predicted probabilities: [0.30441972613334656, 0.19742408394813538, 0.43314653635025024, 0.4970138669013977, 0.4872819781303406, 0.5571728348731995, 0.45604804158210754, 0.5146146416664124, 0.3258282244205475, 0.4745754599571228]\n",
      "Per-sample bit lengths: [1.715866208076477, 0.31729018688201904, 0.8189522624015808, 1.0086419582366943, 1.0371712446212769, 1.1751843690872192, 1.1327422857284546, 1.0427974462509155, 1.6178165674209595, 0.928444504737854]\n",
      "Total bits needed: 10.7949\n",
      "BCE loss (in bits): 10.7949\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Step 1: Fake data\n",
    "torch.manual_seed(0)\n",
    "X = torch.randn(10, 4)  # 10 data points, 4 features\n",
    "y = torch.randint(0, 2, (10,)).float()  # Binary labels\n",
    "\n",
    "# Step 2: Tiny neural net (1-layer logistic reg)\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))  # outputs probabilities\n",
    "\n",
    "model = SimpleClassifier()\n",
    "\n",
    "# Step 3: Get predicted probabilities\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X).squeeze()\n",
    "\n",
    "# Step 4: Compute BCE manually and bit lengths\n",
    "eps = 1e-9  # to avoid log(0)\n",
    "log_probs = - (y * torch.log2(y_pred + eps) + (1 - y) * torch.log2(1 - y_pred + eps))\n",
    "\n",
    "# Total loss = sum of bits needed to encode the labels\n",
    "total_bits = log_probs.sum()\n",
    "\n",
    "# Compare with BCE loss from PyTorch\n",
    "bce_loss = F.binary_cross_entropy(y_pred, y, reduction='sum') / torch.log(torch.tensor(2.0))  # convert from nats to bits\n",
    "\n",
    "print(\"Label truths:\", y.tolist())\n",
    "print(\"Predicted probabilities:\", y_pred.tolist())\n",
    "print(\"Per-sample bit lengths:\", log_probs.tolist())\n",
    "print(f\"Total bits needed: {total_bits.item():.4f}\")\n",
    "print(f\"BCE loss (in bits): {bce_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ True distribution q: [0.6 0.3 0.1]\n",
      "ðŸ”¸ Model prediction p: [0.5 0.4 0.1]\n",
      "\n",
      "Entropy H(q):          1.2955 bits\n",
      "Cross-Entropy H(q, p): 1.3288 bits\n",
      "KL(q || p):            0.0333 bits (extra cost)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ðŸ”¹ True label distribution (ground truth)\n",
    "q = np.array([0.6, 0.3, 0.1])  # Class 0 is most common\n",
    "\n",
    "# ðŸ”¸ Model's predicted distribution\n",
    "p = np.array([0.5, 0.4, 0.1])  # Slightly off\n",
    "\n",
    "# Make sure they're proper distributions\n",
    "assert np.isclose(np.sum(q), 1.0)\n",
    "assert np.isclose(np.sum(p), 1.0)\n",
    "\n",
    "# Function to compute entropy\n",
    "def entropy(dist):\n",
    "    return -np.sum(dist * np.log2(dist + 1e-12))\n",
    "\n",
    "# Function to compute cross-entropy\n",
    "def cross_entropy(q, p):\n",
    "    return -np.sum(q * np.log2(p + 1e-12))\n",
    "\n",
    "# Compute values\n",
    "H_q = entropy(q)\n",
    "H_qp = cross_entropy(q, p)\n",
    "KL_q_p = H_qp - H_q\n",
    "\n",
    "# Display nicely\n",
    "print(\"ðŸ”¹ True distribution q:\", q)\n",
    "print(\"ðŸ”¸ Model prediction p:\", p)\n",
    "print()\n",
    "print(f\"Entropy H(q):          {H_q:.4f} bits\")\n",
    "print(f\"Cross-Entropy H(q, p): {H_qp:.4f} bits\")\n",
    "print(f\"KL(q || p):            {KL_q_p:.4f} bits (extra cost)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact 99th percentile: 123.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "n=1000\n",
    "p=0.1\n",
    "quantile_exact = binom.ppf(0.99, n, p)\n",
    "print(f\"Exact 99th percentile: {quantile_exact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate 99th quantile (q = 0.1300): x = 130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "def kl_divergence(q, p):\n",
    "    return q * np.log(q / p) + (1 - q) * np.log((1 - q) / (1 - p))\n",
    "\n",
    "n = 1000\n",
    "p = 0.1\n",
    "alpha = 0.99\n",
    "\n",
    "threshold = np.log(1 / (1 - alpha)) / n\n",
    "\n",
    "# Solve for q such that D(q || p) â‰ˆ threshold\n",
    "def equation(q):\n",
    "    return kl_divergence(q, p) - threshold\n",
    "\n",
    "q_guess = p + 0.05  # Guess a bit above p\n",
    "q_99 = fsolve(equation, q_guess)[0]\n",
    "x_99 = int(np.ceil(n * q_99))\n",
    "\n",
    "print(f\"Approximate 99th quantile (q = {q_99:.4f}): x = {x_99}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_99 = 0.1300 --> Approx. 99th quantile: x = 130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "def kl(q, p):\n",
    "    return q * np.log(q / p) + (1 - q) * np.log((1 - q) / (1 - p))\n",
    "\n",
    "n = 1000\n",
    "p = 0.1\n",
    "alpha = 0.99\n",
    "\n",
    "# Solve D(q || p) = log(1 / (1 - alpha)) / n\n",
    "target = np.log(1 / (1 - alpha)) / n\n",
    "\n",
    "def to_solve(q):\n",
    "    return kl(q, p) - target\n",
    "\n",
    "q_init = p + 0.05\n",
    "q_99 = fsolve(to_solve, q_init)[0]\n",
    "x_99 = int(np.ceil(n * q_99))\n",
    "\n",
    "print(f\"q_99 = {q_99:.4f} --> Approx. 99th quantile: x = {x_99}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.4689955935892812)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.1*np.log2(0.1)-0.9*np.log2(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000*0.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(8.265462708244986)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_squared=4\n",
    "\n",
    "effective_sample_size = 2**(1/2*np.log2(2*np.pi*np.e*sigma_squared))\n",
    "effective_sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.13598703592091e+96"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**(1000*0.32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/3**4>(1/16*1/2*1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1764705882352941"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.3*0.3)/(0.3*0.3+0.6*0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
