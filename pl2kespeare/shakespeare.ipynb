{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: shakespeare_cpca_layer6_cpc1.npy\n",
      "\n",
      "ðŸŽ­ GPT-2 with Shakespeare latent injected:\n",
      "\n",
      "The nature of intelligence lies in the recognition of the inherent nature of the individual and in the willingness to pursue the individual's interests at all cost. The ability to be free, to exercise one's freedom, to engage in political activity, to participate in a social and political discussion, to engage in social debate, to engage in community service, to participate in other forms of expression, and to participate in the social interaction of the world are the same as those that are innate to the individual.\n",
      "\n",
      "Thus, the individual can have all of the essential qualities, qualities that are unique to him, but that are not in common with all others. Therefore, the individual can only be free\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.linalg import eigh\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Config ---\n",
    "SEED = 42\n",
    "LAYER = 6\n",
    "LAMBDA = 0.0\n",
    "MAX_TOKENS = 130\n",
    "TEMPERATURE = 0.8\n",
    "\n",
    "# Set seed\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# --- Load activations ---\n",
    "X_shakespeare = np.load(\"shakespeare_layer6.npy\")\n",
    "X_maria = np.load(\"maria_layer6.npy\")\n",
    "\n",
    "# --- Normalize ---\n",
    "scaler = StandardScaler()\n",
    "X_foreground = scaler.fit_transform(X_shakespeare)\n",
    "X_background = scaler.transform(X_maria)\n",
    "\n",
    "# --- Contrastive PCA ---\n",
    "alpha = 1.0\n",
    "C_fg = np.cov(X_foreground, rowvar=False)\n",
    "C_bg = np.cov(X_background, rowvar=False)\n",
    "C_contrastive = C_fg - alpha * C_bg\n",
    "\n",
    "eigvals, eigvecs = eigh(C_contrastive)\n",
    "idx = np.argsort(eigvals)[::-1]\n",
    "eigvecs = eigvecs[:, idx]\n",
    "cpc1 = eigvecs[:, 0]\n",
    "\n",
    "# --- Save Shakespeare vector ---\n",
    "np.save(\"shakespeare_cpca_layer6_cpc1.npy\", cpc1)\n",
    "print(\"âœ… Saved: shakespeare_cpca_layer6_cpc1.npy\")\n",
    "\n",
    "# --- Inject into GPT-2 ---\n",
    "cpc1 = torch.tensor(cpc1, dtype=torch.float32)\n",
    "\n",
    "# Load model + tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "cpc1 = cpc1.to(device)\n",
    "\n",
    "# Prompt\n",
    "prompt = \"The nature of intelligence lies in\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=True).to(device)\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "# Forward pass to layer\n",
    "with torch.no_grad():\n",
    "    outputs = model.transformer(**inputs, output_hidden_states=True)\n",
    "    residual = outputs.hidden_states[LAYER][0]  # [seq_len, 768]\n",
    "\n",
    "# Inject Shakespeare latent into final token\n",
    "residual[-1] += LAMBDA * cpc1\n",
    "\n",
    "# Generate one token with injection\n",
    "with torch.no_grad():\n",
    "    logits = model.lm_head(residual.unsqueeze(0))\n",
    "    next_token_id = torch.argmax(logits[0, -1]).unsqueeze(0)\n",
    "    input_ids = torch.cat([input_ids, next_token_id.unsqueeze(0)], dim=1)\n",
    "    attention_mask = torch.cat([attention_mask, torch.ones_like(next_token_id.unsqueeze(0))], dim=1)\n",
    "\n",
    "# Full continuation\n",
    "output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_new_tokens=MAX_TOKENS,\n",
    "    do_sample=True,\n",
    "    temperature=TEMPERATURE,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"\\nðŸŽ­ GPT-2 with Shakespeare latent injected:\\n\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load full cPCA components from earlier runs (each shape: [768, n_components])\n",
    "maria_cpca = np.load(\"cpca_layer6_cpc1.npy\") if \"cpca_layer6_cpc1.npy\" in locals() else None\n",
    "shakespeare_cpca = np.load(\"shakespeare_cpca_layer6_cpc1.npy\") if \"shakespeare_cpca_layer6_cpc1.npy\" in locals() else None\n",
    "\n",
    "# Option 1: You already have the components in memory â€” just save them\n",
    "# Option 2: If you have them saved as .npy from contrastive PCA, load them manually like this:\n",
    "# maria_cpca = np.load(\"cpca_layer6_components.npy\")[:, 0]  # first component\n",
    "# shakespeare_cpca = np.load(\"shakespeare_layer6_components.npy\")[:, 0]\n",
    "\n",
    "# Save them under the names used in the generation script\n",
    "if maria_cpca is not None:\n",
    "    np.save(\"freedom_latent_maria_layer6.npy\", maria_cpca)\n",
    "    print(\"âœ… Saved Maria latent: freedom_latent_maria_layer6.npy\")\n",
    "\n",
    "if shakespeare_cpca is not None:\n",
    "    np.save(\"shakespeare_cpca_layer6_cpc1.npy\", shakespeare_cpca)\n",
    "    print(\"âœ… Saved Shakespeare latent: shakespeare_cpca_layer6_cpc1.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
